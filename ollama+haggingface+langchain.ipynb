{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T04:54:08.751294Z",
     "start_time": "2025-09-04T04:53:21.793545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "llm = Ollama(model=\"llama2\")\n",
    "\n",
    "llm.invoke([\n",
    "    HumanMessage(\"hello, I am Sifat\"),\n",
    "])"
   ],
   "id": "be93e661eb119900",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAssistant: Hello Sifat! It's nice to meet you. How can I assist you today? Is there something you would like to talk about or ask?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T05:04:48.911070Z",
     "start_time": "2025-09-04T05:04:40.754223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.schema import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# -------------------------\n",
    "# Workflow definition\n",
    "# -------------------------\n",
    "workflow = StateGraph(dict)  # Using plain dict as state\n",
    "\n",
    "# -------------------------\n",
    "# Model setup\n",
    "# -------------------------\n",
    "llm = Ollama(model=\"llama2\")  # Make sure you have pulled this model\n",
    "\n",
    "# -------------------------\n",
    "# Node: call LLM\n",
    "# -------------------------\n",
    "def call_model(state: dict):\n",
    "    # The LLM expects a list of messages\n",
    "    messages = state.get(\"messages\", [])\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Append assistant response to history\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    state[\"messages\"] = messages\n",
    "    state[\"response\"] = response\n",
    "    return state\n",
    "\n",
    "# -------------------------\n",
    "# Add node and edge correctly\n",
    "# -------------------------\n",
    "workflow.add_node(\"chat_model\", call_model)  # Add node only once\n",
    "workflow.add_edge(START, \"chat_model\")       # Add edge after node exists\n",
    "\n",
    "# -------------------------\n",
    "# Memory saver\n",
    "# -------------------------\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# -------------------------\n",
    "# Query function\n",
    "# -------------------------\n",
    "def ask_question(query: str, thread_id: str = \"session_1\"):\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    result = app.invoke(input=state, config=config)\n",
    "\n",
    "    # Save updated state to memory automatically happens via checkpointer\n",
    "    return result[\"response\"]\n",
    "\n",
    "# -------------------------\n",
    "# Run chat loop\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        try:\n",
    "            message = input(\"Your message: \")\n",
    "        except EOFError:\n",
    "            print(\"\\nExiting chat.\")\n",
    "            break\n",
    "        if not message.strip():\n",
    "            continue\n",
    "\n",
    "        answer = ask_question(message)\n",
    "        print(\"\\nResponse:\\n\", answer)\n"
   ],
   "id": "d03d7325ee657ce1",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InMemorySaver' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 74\u001B[39m\n\u001B[32m     71\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m message.strip():\n\u001B[32m     72\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m74\u001B[39m answer = \u001B[43mask_question\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mResponse:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m, answer)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 47\u001B[39m, in \u001B[36mask_question\u001B[39m\u001B[34m(query, thread_id)\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mask_question\u001B[39m(query: \u001B[38;5;28mstr\u001B[39m, thread_id: \u001B[38;5;28mstr\u001B[39m = \u001B[33m\"\u001B[39m\u001B[33msession_1\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m     46\u001B[39m     \u001B[38;5;66;03m# Load previous conversation from memory if it exists\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m     previous_state = \u001B[43mmemory\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m(thread_id) \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[32m     48\u001B[39m     messages = previous_state.get(\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, [])\n\u001B[32m     50\u001B[39m     \u001B[38;5;66;03m# Add new user message\u001B[39;00m\n",
      "\u001B[31mAttributeError\u001B[39m: 'InMemorySaver' object has no attribute 'load'"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
